{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\daniel.hwang\\study\\ml\\fullstack_gpt\\env2\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Potato is a staple food crop and is one of the most widely grown and consumed vegetables in the world. It is a type of tuber that is grown underground in soil and is harvested when it reaches maturity. Potatoes are edible and can be cooked in many different ways, including boiling, frying, roasting, and baking. They can also be stored for long periods of time and are used in a variety of dishes, including soups, salads,'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms.huggingface_hub import HuggingFaceHub\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"[INST]What is the meaning of {word}[/INST]\")\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"llama3.1ai/llama3.1-7B-Instruct-v0.3\",\n",
    ")\n",
    "llm.client.api_url = 'https://api-inference.huggingface.co/models/llama3.1ai/llama3.1-7B-Instruct-v0.1'\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "chain.invoke({\n",
    "    \"word\": \"potato\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': \"Can you please let us know more details about your 265 gram brake rotor? Your question seems to be about a specific car part, but you didn't provide enough details for a clear answer. Here's some general information about car brake rotors that might help:\\n\\n1. Material: Brake rotors are typically made of cast iron, though some manufacturers use composite materials in newer models for weight reduction.\\n\\n2. Size: The size of the brake rotor can vary significantly between different makes,\"}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/llama3.1ai/llama3.1-7B-Instruct-v0.3\"\n",
    "headers = {\n",
    "    \"Authorization\": \"Bearer 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\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"x-use-cache\": \"false\"\n",
    "}\n",
    "data = {\n",
    "    # \"inputs\": \"[INST]Can you please let us know more details about your [/INST]\"\n",
    "    \"inputs\": \"Can you please let us know more details about your \"\n",
    "}\n",
    "response = requests.post(API_URL, headers=headers, json=data)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of France is Paris. Paris is located in the north-central part of"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient(\n",
    "    \"llama3.1ai/llama3.1-7B-Instruct-v0.3\",\n",
    ")\n",
    "\n",
    "for message in client.text_generation(\n",
    "\t\"[INST]What is the capital of France?[/INST]\",\n",
    "):\n",
    "    print(message, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The capital of France is Paris. Paris is renowned worldwide for its cultural, artistic, and architectural attractions, such as the Eiffel Tower, Louvre Museum, Notre-Dame Cathedral, and Palace of Versailles. It's one of the most famous cities globally for its significant contributions to arts, sciences, and fashion."
     ]
    }
   ],
   "source": [
    "# Not working : https://huggingface.co/llama3.1ai/llama3.1-7B-Instruct-v0.3?inference_api=true\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient(\n",
    "    \"llama3.1ai/llama3.1-7B-Instruct-v0.3\",\n",
    ")\n",
    "\n",
    "for message in client.chat_completion(\n",
    "\tmessages=[{\"role\": \"user\", \"content\": \"What is the capital of France?\"}],\n",
    "\tstream=True,\n",
    "):\n",
    "    print(message.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The capital of France is Paris.</s>"
     ]
    }
   ],
   "source": [
    "# Working\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient(\n",
    "    \"llama3.1ai/llama3.1-7B-Instruct-v0.3\",\n",
    ")\n",
    "\n",
    "prompt = \"[INST]Human: What is the capital of France?\\n\\nAssistant:[/INST]\"\n",
    "\n",
    "for token in client.text_generation(\n",
    "    prompt,\n",
    "    max_new_tokens=500,\n",
    "    stream=True,\n",
    "):\n",
    "    print(token, end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
